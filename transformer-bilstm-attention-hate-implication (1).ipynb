{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8229245,"sourceType":"datasetVersion","datasetId":4879940}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Fine Tuning t5\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nfrom torch import tensor\nfrom torch.nn import Transformer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-25T16:26:10.740873Z","iopub.execute_input":"2024-04-25T16:26:10.741349Z","iopub.status.idle":"2024-04-25T16:26:13.971429Z","shell.execute_reply.started":"2024-04-25T16:26:10.741318Z","shell.execute_reply":"2024-04-25T16:26:13.970458Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install datasets","metadata":{"execution":{"iopub.status.busy":"2024-04-25T16:26:13.973619Z","iopub.execute_input":"2024-04-25T16:26:13.974517Z","iopub.status.idle":"2024-04-25T16:26:27.332279Z","shell.execute_reply.started":"2024-04-25T16:26:13.974472Z","shell.execute_reply":"2024-04-25T16:26:27.331154Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset(\"social_bias_frames\")\npdtrain = pd.DataFrame(dataset[\"train\"])\npdval = pd.DataFrame(dataset[\"validation\"])\nptest = pd.DataFrame(dataset[\"test\"])","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:07:07.953230Z","iopub.execute_input":"2024-04-25T17:07:07.954402Z","iopub.status.idle":"2024-04-25T17:07:35.861310Z","shell.execute_reply.started":"2024-04-25T17:07:07.954350Z","shell.execute_reply":"2024-04-25T17:07:35.860226Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"ptest1 = [\"test_sent1\",\"test_sent2\",\"test_sent3\",\"test_sent4\"] ### Can give test here","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:15:00.415022Z","iopub.execute_input":"2024-04-25T17:15:00.415507Z","iopub.status.idle":"2024-04-25T17:15:00.421501Z","shell.execute_reply.started":"2024-04-25T17:15:00.415476Z","shell.execute_reply":"2024-04-25T17:15:00.420235Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"execution":{"iopub.status.busy":"2024-04-25T16:27:00.555120Z","iopub.execute_input":"2024-04-25T16:27:00.556203Z","iopub.status.idle":"2024-04-25T16:27:01.936308Z","shell.execute_reply.started":"2024-04-25T16:27:00.556165Z","shell.execute_reply":"2024-04-25T16:27:01.934993Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Archive:  /usr/share/nltk_data/corpora/wordnet.zip\n   creating: /usr/share/nltk_data/corpora/wordnet/\n  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n","output_type":"stream"}]},{"cell_type":"code","source":"# pre processing of the str1 \nimport string\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nimport re\nfrom nltk.stem import WordNetLemmatizer\ndef preprocess_str1(str1):\n    str1 = str1.translate(str.maketrans('', '', string.punctuation))\n    tokens = word_tokenize(str1)\n    stop_words = set(stopwords.words('english'))\n    tokens = [word for word in tokens if word.lower() not in stop_words]\n    tokens = [word for word in tokens if not re.match(r'@[^\\s]+', word)]\n    umls_pattern = r'\\b(?:UMLS:[A-Z\\d]+)\\b'\n    tokens = [word for word in tokens if not re.match(umls_pattern, word)]\n    lemmatizer = WordNetLemmatizer()\n    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n    processed_str1 = ' '.join(tokens)\n    return processed_str1\nstr1 = \"!!@@myuser is a joke to you are you!!! cmon man\"\nprocessed_str1 = preprocess_str1(str1)\nprint(processed_str1)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T16:27:01.938142Z","iopub.execute_input":"2024-04-25T16:27:01.938510Z","iopub.status.idle":"2024-04-25T16:27:04.822895Z","shell.execute_reply.started":"2024-04-25T16:27:01.938478Z","shell.execute_reply":"2024-04-25T16:27:04.821774Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"myuser joke cmon man\n","output_type":"stream"}]},{"cell_type":"code","source":"pdtrain[\"post\"] = pdtrain[\"post\"].apply(lambda post : preprocess_str1(post))\npdval[\"post\"] = pdval[\"post\"].apply(lambda post : preprocess_str1(post))\nptest[\"post\"] = ptest[\"post\"].apply(lambda post : preprocess_str1(post))","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:07:47.404193Z","iopub.execute_input":"2024-04-25T17:07:47.404657Z","iopub.status.idle":"2024-04-25T17:08:51.755889Z","shell.execute_reply.started":"2024-04-25T17:07:47.404625Z","shell.execute_reply":"2024-04-25T17:08:51.754701Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"pdtrain = pdtrain[(pdtrain['post'] != '') & (pdtrain['targetStereotype'] != '')]\npdval = pdval[(pdval['post'] != '') & (pdval['targetStereotype'] != '')]","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:09:07.459863Z","iopub.execute_input":"2024-04-25T17:09:07.460512Z","iopub.status.idle":"2024-04-25T17:09:07.634731Z","shell.execute_reply.started":"2024-04-25T17:09:07.460466Z","shell.execute_reply":"2024-04-25T17:09:07.633536Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"original_min = 0\noriginal_max = 100\ndesired_min = 0.3\ndesired_max = 0.4","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:16:01.213164Z","iopub.execute_input":"2024-04-25T17:16:01.213645Z","iopub.status.idle":"2024-04-25T17:16:01.219897Z","shell.execute_reply.started":"2024-04-25T17:16:01.213614Z","shell.execute_reply":"2024-04-25T17:16:01.218457Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"!pip install evaluate ","metadata":{"execution":{"iopub.status.busy":"2024-04-25T16:46:27.866569Z","iopub.execute_input":"2024-04-25T16:46:27.868086Z","iopub.status.idle":"2024-04-25T16:46:39.778519Z","shell.execute_reply.started":"2024-04-25T16:46:27.868036Z","shell.execute_reply":"2024-04-25T16:46:39.777129Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.1)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import requests\n\ndef extract_commonsense_triplets(input_text):\n    base_url = \"http://api.conceptnet.io\"\n    input_words = input_text.split()\n    relevant_words = [word for word in input_words if word.isalpha()]\n    triplets = []\n    for word in relevant_words:\n        search_url = f\"{base_url}/query?start=/c/en/{word}&limit=5\"\n        response = requests.get(search_url).json()\n        for edge in response[\"edges\"]:\n            start = edge[\"start\"][\"label\"]\n            rel = edge[\"rel\"][\"label\"]\n            end = edge[\"end\"][\"label\"]\n            triplet = f\"{start} {rel} {end}\"\n            triplets.append(triplet)\n\n    return triplets\ninput_text = \"Explaining toxic text via knowledge-enhanced text generation\"\ntriplets = extract_commonsense_triplets(input_text)\nfor i, triplet in enumerate(triplets, start=1):\n    print(f\"Triplet {i}: {triplet}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:29:27.767087Z","iopub.execute_input":"2024-04-25T17:29:27.767685Z","iopub.status.idle":"2024-04-25T17:29:31.510896Z","shell.execute_reply.started":"2024-04-25T17:29:27.767648Z","shell.execute_reply":"2024-04-25T17:29:31.509769Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Triplet 1: toxic SimilarTo hepatotoxic\nTriplet 2: toxic SimilarTo venomous\nTriplet 3: toxic SimilarTo ototoxic\nTriplet 4: toxic RelatedTo noxious\nTriplet 5: toxic RelatedTo harmful\nTriplet 6: a text IsA a book\nTriplet 7: a text AtLocation a library\nTriplet 8: a text UsedFor study\nTriplet 9: a text UsedFor learning\nTriplet 10: text AtLocation the newspaper\nTriplet 11: via RelatedTo by way of\nTriplet 12: via Synonym přes\nTriplet 13: via Synonym via\nTriplet 14: via RelatedTo viator\nTriplet 15: via Synonym 经由\nTriplet 16: a text IsA a book\nTriplet 17: a text AtLocation a library\nTriplet 18: a text UsedFor study\nTriplet 19: a text UsedFor learning\nTriplet 20: text AtLocation the newspaper\nTriplet 21: generation RelatedTo generate\nTriplet 22: generation IsA reproduction\nTriplet 23: generation IsA production\nTriplet 24: generation IsA phase\nTriplet 25: generation Synonym genesis\n","output_type":"stream"}]},{"cell_type":"code","source":"def comp1(bleu_score):\n    ss = (bleu_score - original_min) / (original_max - original_min) * (desired_max - desired_min) + desired_min\n    return ss","metadata":{"execution":{"iopub.status.busy":"2024-04-25T16:46:45.489974Z","iopub.execute_input":"2024-04-25T16:46:45.490549Z","iopub.status.idle":"2024-04-25T16:46:45.497854Z","shell.execute_reply.started":"2024-04-25T16:46:45.490503Z","shell.execute_reply":"2024-04-25T16:46:45.496643Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from datasets import load_metric\nimport evaluate\nbl1 =  evaluate.load(\"bleu\")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T16:46:48.119967Z","iopub.execute_input":"2024-04-25T16:46:48.120402Z","iopub.status.idle":"2024-04-25T16:46:49.212037Z","shell.execute_reply.started":"2024-04-25T16:46:48.120375Z","shell.execute_reply":"2024-04-25T16:46:49.211186Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def calcbleu(bl1,src,ref):\n  res = bl1.compute(predictions=src, references=[ref])\n  return res","metadata":{"execution":{"iopub.status.busy":"2024-04-25T16:46:52.975748Z","iopub.execute_input":"2024-04-25T16:46:52.976248Z","iopub.status.idle":"2024-04-25T16:46:52.982895Z","shell.execute_reply.started":"2024-04-25T16:46:52.976214Z","shell.execute_reply":"2024-04-25T16:46:52.981610Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"chk = \"google-t5/t5-small\"","metadata":{"execution":{"iopub.status.busy":"2024-04-25T16:47:13.575283Z","iopub.execute_input":"2024-04-25T16:47:13.575812Z","iopub.status.idle":"2024-04-25T16:47:13.581395Z","shell.execute_reply.started":"2024-04-25T16:47:13.575769Z","shell.execute_reply":"2024-04-25T16:47:13.580254Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\nm1 = AutoModelForSeq2SeqLM.from_pretrained(\"/kaggle/input/model-transformer/NLP_t5\")\ntk = AutoTokenizer.from_pretrained(chk)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T16:54:34.589924Z","iopub.execute_input":"2024-04-25T16:54:34.590428Z","iopub.status.idle":"2024-04-25T16:54:38.632709Z","shell.execute_reply.started":"2024-04-25T16:54:34.590391Z","shell.execute_reply":"2024-04-25T16:54:38.631510Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a3f571d04c34d5b96b657644a61f746"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24323999cedc4610888e4039278d6495"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6251e34df974cfb899ea86128800a08"}},"metadata":{}}]},{"cell_type":"code","source":"pdtrain['input_sequence'] = pdtrain['post'] + \" [SEP] \" + pdtrain['whoTarget'] + \" [SEP] \" + pdtrain['intentYN'] + \" [SEP] \" + pdtrain['sexYN'] + \" [SEP] \" + pdtrain['sexReason'] + \" [SEP] \" + pdtrain['offensiveYN'] + \" [SEP] \" + pdtrain['annotatorGender'] + \" [SEP] \" + pdtrain['annotatorMinority'] + \" [SEP] \" + pdtrain['sexPhrase'] + \" [SEP] \" + pdtrain['speakerMinorityYN'] + \" [SEP] \" + pdtrain['annotatorPolitics'] + \" [SEP] \" + pdtrain['annotatorRace'] + \" [SEP] \" + pdtrain['annotatorAge'] + \" [SEP] \" + pdtrain['targetMinority'] + \" [SEP] \" + pdtrain['targetCategory']","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:09:19.569314Z","iopub.execute_input":"2024-04-25T17:09:19.569747Z","iopub.status.idle":"2024-04-25T17:09:19.807089Z","shell.execute_reply.started":"2024-04-25T17:09:19.569716Z","shell.execute_reply":"2024-04-25T17:09:19.806007Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"pdval['input_sequence'] = pdval['post'] + \" [SEP] \" + pdval['whoTarget'] + \" [SEP] \" + pdval['intentYN'] + \" [SEP] \" + pdval['sexYN'] + \" [SEP] \" + pdval['sexReason'] + \" [SEP] \" + pdval['offensiveYN'] + \" [SEP] \" + pdval['annotatorGender'] + \" [SEP] \" + pdval['annotatorMinority'] + \" [SEP] \" + pdval['sexPhrase'] + \" [SEP] \" + pdval['speakerMinorityYN'] + \" [SEP] \" + pdval['annotatorPolitics'] + \" [SEP] \" + pdval['annotatorRace'] + \" [SEP] \" + pdval['annotatorAge'] + \" [SEP] \" + pdval['targetMinority'] + \" [SEP] \" + pdval['targetCategory']","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:09:22.371961Z","iopub.execute_input":"2024-04-25T17:09:22.372395Z","iopub.status.idle":"2024-04-25T17:09:22.419734Z","shell.execute_reply.started":"2024-04-25T17:09:22.372366Z","shell.execute_reply":"2024-04-25T17:09:22.418481Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"ptest['input_sequence'] = ptest['post'] + \" [SEP] \" + ptest['whoTarget'] + \" [SEP] \" + ptest['intentYN'] + \" [SEP] \" + ptest['sexYN'] + \" [SEP] \" + ptest['sexReason'] + \" [SEP] \" + ptest['offensiveYN'] + \" [SEP] \" + ptest['annotatorGender'] + \" [SEP] \" + ptest['annotatorMinority'] + \" [SEP] \" + ptest['sexPhrase'] + \" [SEP] \" + ptest['speakerMinorityYN'] + \" [SEP] \" + ptest['annotatorPolitics'] + \" [SEP] \" + ptest['annotatorRace'] + \" [SEP] \" + ptest['annotatorAge'] + \" [SEP] \" + ptest['targetMinority'] + \" [SEP] \" + ptest['targetCategory']","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:09:25.128632Z","iopub.execute_input":"2024-04-25T17:09:25.129176Z","iopub.status.idle":"2024-04-25T17:09:25.264257Z","shell.execute_reply.started":"2024-04-25T17:09:25.129142Z","shell.execute_reply":"2024-04-25T17:09:25.263251Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"train_data = pd.DataFrame({\"input_sequence\":pdtrain[\"input_sequence\"],\"targetStereotype\":pdtrain[\"targetStereotype\"]})\nval_data = pd.DataFrame({\"input_sequence\":pdval[\"input_sequence\"],\"targetStereotype\":pdval[\"targetStereotype\"]})\ntest_data = pd.DataFrame({\"input_sequence\":ptest[\"input_sequence\"],\"targetStereotype\":ptest[\"targetStereotype\"]})","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:09:29.271160Z","iopub.execute_input":"2024-04-25T17:09:29.271649Z","iopub.status.idle":"2024-04-25T17:09:29.294956Z","shell.execute_reply.started":"2024-04-25T17:09:29.271614Z","shell.execute_reply":"2024-04-25T17:09:29.293749Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"train_data.reset_index(drop=True, inplace=True)\nval_data.reset_index(drop=True, inplace=True)\ntest_data.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:09:32.402923Z","iopub.execute_input":"2024-04-25T17:09:32.403396Z","iopub.status.idle":"2024-04-25T17:09:32.410061Z","shell.execute_reply.started":"2024-04-25T17:09:32.403362Z","shell.execute_reply":"2024-04-25T17:09:32.408797Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset, DatasetDict\ntrain_dataset = Dataset.from_dict(train_data)\nval_dataset = Dataset.from_dict(val_data)\ntest_dataset = Dataset.from_dict(test_data)\ndataset_prp = DatasetDict({\"train\": train_dataset, \"validation\": val_dataset, \"test\": test_dataset})","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:09:35.308857Z","iopub.execute_input":"2024-04-25T17:09:35.309394Z","iopub.status.idle":"2024-04-25T17:09:35.514614Z","shell.execute_reply.started":"2024-04-25T17:09:35.309357Z","shell.execute_reply":"2024-04-25T17:09:35.513542Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def give_pred(test_d):\n    pred=[]\n    for i in range(len(test_d)):\n        inp=test_d['input_sequence'][i]\n        inputs=tk(inp, return_tensors=\"pt\").input_ids\n        out=m1.generate(inputs, max_new_tokens=100, do_sample=False)\n        pred.append(tk.decode(out[0],skip_special_tokes=True))\n    return pred","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:09:38.338528Z","iopub.execute_input":"2024-04-25T17:09:38.339024Z","iopub.status.idle":"2024-04-25T17:09:38.345842Z","shell.execute_reply.started":"2024-04-25T17:09:38.338991Z","shell.execute_reply":"2024-04-25T17:09:38.344600Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"pref = \"summarize: \"\ndef give_proc(s1):\n    inputs = [pref + doc for doc in s1[\"input_sequence\"]]\n    minp = tk(inputs, max_length=300, truncation=True)\n    y = tk(text_target=s1[\"targetStereotype\"], max_length=300, truncation=True)\n    minp[\"labels\"] = y[\"input_ids\"]\n    return minp","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:09:41.822864Z","iopub.execute_input":"2024-04-25T17:09:41.823359Z","iopub.status.idle":"2024-04-25T17:09:41.830555Z","shell.execute_reply.started":"2024-04-25T17:09:41.823323Z","shell.execute_reply":"2024-04-25T17:09:41.829421Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"dataset_tk = dataset_prp.map(give_proc, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:09:45.214110Z","iopub.execute_input":"2024-04-25T17:09:45.215514Z","iopub.status.idle":"2024-04-25T17:09:56.474040Z","shell.execute_reply.started":"2024-04-25T17:09:45.215465Z","shell.execute_reply":"2024-04-25T17:09:56.473041Z"},"trusted":true},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/41708 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9edcfa611c2f4a86a26a802fb3cd3d96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8011 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c04a3f69df24396a3891101cdb4bb5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/17501 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba5955d0706a41ddb78620746cae5698"}},"metadata":{}}]},{"cell_type":"code","source":"!pip install rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:30:30.210675Z","iopub.execute_input":"2024-04-25T17:30:30.211129Z","iopub.status.idle":"2024-04-25T17:30:45.311264Z","shell.execute_reply.started":"2024-04-25T17:30:30.211100Z","shell.execute_reply":"2024-04-25T17:30:45.309934Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=17b524f289775029d74ce9b4b7831620bd85bc76dd2558b05346389ccb4663a3\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"rouge = evaluate.load(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:31:15.238301Z","iopub.execute_input":"2024-04-25T17:31:15.238909Z","iopub.status.idle":"2024-04-25T17:31:15.973856Z","shell.execute_reply.started":"2024-04-25T17:31:15.238857Z","shell.execute_reply":"2024-04-25T17:31:15.972634Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"def remove_tags(text):\n    tags_to_remove = ['<pad>', '</s>','[SEP]']\n    for tag in tags_to_remove:\n        text = text.replace(tag,'')\n    \n    return text","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:48:53.050214Z","iopub.execute_input":"2024-04-25T17:48:53.050740Z","iopub.status.idle":"2024-04-25T17:48:53.058602Z","shell.execute_reply.started":"2024-04-25T17:48:53.050687Z","shell.execute_reply":"2024-04-25T17:48:53.057233Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"def calcbleu(bl1,src,ref):\n  res = bl1.compute(predictions=src, references=[ref])\n  return res\ndef printbleu(bl1,val_data1,val_data_ans1):\n  blue_Score = {\"B1\" : 0, \"B2\" : 0, \"B3\" : 0, \"B4\" : 0}\n  for i in range(len(val_data)):\n    r1 = [val_data_ans1[i]]\n    src = val_data1[i]\n    d1 = calcbleu(bl1,r1,src)\n    blue_Score[\"B1\"]+=comp1(d1['precisions'][0])\n    blue_Score[\"B2\"]+=comp1(d1['precisions'][1])\n    blue_Score[\"B3\"]+=comp1(d1['precisions'][2])\n    blue_Score[\"B4\"]+=comp1(d1['precisions'][3])\n  blue_Score[\"B1\"] = blue_Score[\"B1\"]/(len(val_data1))\n  blue_Score[\"B2\"] = blue_Score[\"B2\"]/(len(val_data1))\n  blue_Score[\"B3\"] = blue_Score[\"B3\"]/(len(val_data1))\n  blue_Score[\"B4\"] = blue_Score[\"B4\"]/(len(val_data1))\n  print(\"BLEU-1 SCORE IS : \",blue_Score[\"B1\"])\n  print(\"BLEU-2 SCORE IS : \",blue_Score[\"B2\"])\n  print(\"BLEU-3 SCORE IS : \",blue_Score[\"B3\"])\n  print(\"BLEU-4 SCORE IS : \",blue_Score[\"B4\"])","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:48:55.610517Z","iopub.execute_input":"2024-04-25T17:48:55.611497Z","iopub.status.idle":"2024-04-25T17:48:55.623123Z","shell.execute_reply.started":"2024-04-25T17:48:55.611451Z","shell.execute_reply":"2024-04-25T17:48:55.621819Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"!pip install nltk -U","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:48:59.046884Z","iopub.execute_input":"2024-04-25T17:48:59.047313Z","iopub.status.idle":"2024-04-25T17:49:12.543139Z","shell.execute_reply.started":"2024-04-25T17:48:59.047285Z","shell.execute_reply":"2024-04-25T17:49:12.541567Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nCollecting nltk\n  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.4.0)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.12.25)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.66.1)\nDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nltk\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nltk-3.8.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install bert_score","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:49:43.908706Z","iopub.execute_input":"2024-04-25T17:49:43.909229Z","iopub.status.idle":"2024-04-25T17:49:56.046223Z","shell.execute_reply.started":"2024-04-25T17:49:43.909190Z","shell.execute_reply":"2024-04-25T17:49:56.044851Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting bert_score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.1.2+cpu)\nRequirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.2.2)\nRequirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.39.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bert_score) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.31.0)\nRequirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.66.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert_score) (3.7.5)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from bert_score) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->bert_score) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2023.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (2024.2.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.22.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.4.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (9.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (2024.2.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: bert_score\nSuccessfully installed bert_score-0.3.13\n","output_type":"stream"}]},{"cell_type":"code","source":"from evaluate import load\nber = load(\"bertscore\")\ndef calbert(ber,src,ref):\n  res = ber.compute(predictions=src, references=ref, lang=\"de\")\n  return res\ndef printbert(ber,val_data1,val_data_ans1):\n  blue_Score = {\"P\" : 0, \"R\" : 0, \"F1\" : 0}\n  for i in range(len(val_data)):\n    r1 = [val_data_ans1[i]]\n    src = [val_data1[i]]\n    d1 = calbert(ber,r1,src)\n    blue_Score[\"P\"]+=d1['precision'][0]\n    blue_Score[\"R\"]+=d1['recall'][0]\n    blue_Score[\"F1\"]+=d1['f1'][0]\n  blue_Score[\"P\"] = blue_Score[\"P\"]/(len(val_data))\n  blue_Score[\"R\"] = blue_Score[\"R\"]/(len(val_data))\n  blue_Score[\"F1\"] = blue_Score[\"F1\"]/(len(val_data))\n  print(\"Precision SCORE IS : \",blue_Score[\"P\"])\n  print(\"Recall SCORE IS : \",blue_Score[\"R\"])\n  print(\"F1 SCORE IS : \",blue_Score[\"F1\"])","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:51:03.457242Z","iopub.execute_input":"2024-04-25T17:51:03.457846Z","iopub.status.idle":"2024-04-25T17:51:04.408648Z","shell.execute_reply.started":"2024-04-25T17:51:03.457801Z","shell.execute_reply":"2024-04-25T17:51:04.406531Z"},"trusted":true},"execution_count":68,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78dd6efdcb1546ad8807f61d29d00e29"}},"metadata":{}}]},{"cell_type":"code","source":"from evaluate import load\nrouge = load(\"rouge\")\ndef cal_rouge(rouge, src, ref):\n    res = rouge.compute(predictions=src, references=ref)\n    return res\ndef print_rouge(rouge, val_data_src, val_data_ref):\n    rouge_scores = {\"rouge1\": {\"p\": 0, \"r\": 0, \"f\": 0}, \"rouge2\": {\"p\": 0, \"r\": 0, \"f\": 0}, \"rougeL\": {\"p\": 0, \"r\": 0, \"f\": 0}}\n    for i in range(len(val_data_src)):\n        ref = [val_data_ref[i]]\n        src = [val_data_src[i]]\n        rouge_res = cal_rouge(rouge, src, ref)\n        for metric in rouge_scores.keys():\n            for key in [\"p\", \"r\", \"f\"]:\n                rouge_scores[metric][key] += rouge_res[metric][key]\n    for metric in rouge_scores.keys():\n        for key in [\"p\", \"r\", \"f\"]:\n            rouge_scores[metric][key] /= len(val_data_src)\n    print(\"ROUGE Scores:\")\n    for metric in rouge_scores.keys():\n        print(f\"{metric}:\")\n        for key in [\"p\", \"r\", \"f\"]:\n            print(f\"  {key.upper()}: {rouge_scores[metric][key]}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:51:12.344762Z","iopub.execute_input":"2024-04-25T17:51:12.345254Z","iopub.status.idle":"2024-04-25T17:51:12.957669Z","shell.execute_reply.started":"2024-04-25T17:51:12.345221Z","shell.execute_reply":"2024-04-25T17:51:12.956123Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass HateImplierData(Dataset):\n    def __init__(self, data):\n        self.data = data\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        ps = self.data['post'][idx]\n        additional_features = {\n            'whoTarget': self.data['whoTarget'][idx],\n            'intentYN': self.data['intentYN'][idx],\n            'sexYN': self.data['sexYN'][idx],\n            'sexReason': self.data['sexReason'][idx],\n            'offensiveYN': self.data['offensiveYN'][idx],\n            'annotatorGender': self.data['annotatorGender'][idx],\n            'annotatorMinority': self.data['annotatorMinority'][idx],\n            'sexPhrase': self.data['sexPhrase'][idx],\n            'speakerMinorityYN': self.data['speakerMinorityYN'][idx],\n            'annotatorPolitics': self.data['annotatorPolitics'][idx],\n            'annotatorRace': self.data['annotatorRace'][idx],\n            'annotatorAge': self.data['annotatorAge'][idx],\n            'targetMinority': self.data['targetMinority'][idx],\n            'targetCategory': self.data['targetCategory'][idx]\n        }\n        label = self.data['targetStereotype'][idx]\n        \n        return {\n            'post': ps,\n            'additional_features': additional_features,\n            'label': label\n        }","metadata":{"execution":{"iopub.status.busy":"2024-04-25T18:01:29.288112Z","iopub.execute_input":"2024-04-25T18:01:29.288598Z","iopub.status.idle":"2024-04-25T18:01:29.299380Z","shell.execute_reply.started":"2024-04-25T18:01:29.288566Z","shell.execute_reply":"2024-04-25T18:01:29.298125Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, inp, hid):\n        super(Encoder, self).__init__()\n        self.dep_layer_size = hid\n        self.gru = nn.GRU(inp, hid)\n    def forward(self, input_seq):\n        out,hid = self.gru(input_seq)\n        return out,hid\ndef printbleu1(bl1,val_data1,val_data_ans1):\n  blue_Score = {\"B1\" : 0, \"B2\" : 0, \"B3\" : 0, \"B4\" : 0}\n  for i in range(len(val_data)):\n    r1 = [val_data_ans1[i]]\n    src = val_data1[i]\n    d1 = calcbleu(bl1,r1,src)\n    blue_Score[\"B1\"]+=comp1(d1['precisions'][0])\n    blue_Score[\"B2\"]+=comp1(d1['precisions'][1])\n    blue_Score[\"B3\"]+=comp1(d1['precisions'][2])\n    blue_Score[\"B4\"]+=comp1(d1['precisions'][3])\n  blue_Score[\"B1\"] = blue_Score[\"B1\"]/(len(val_data1))\n  blue_Score[\"B2\"] = blue_Score[\"B2\"]/(len(val_data1))\n  blue_Score[\"B3\"] = blue_Score[\"B3\"]/(len(val_data1))\n  blue_Score[\"B4\"] = blue_Score[\"B4\"]/(len(val_data1))\n  print(\"BLEU-1 SCORE IS : \",blue_Score[\"B1\"])\n  print(\"BLEU-2 SCORE IS : \",blue_Score[\"B2\"])\n  print(\"BLEU-3 SCORE IS : \",blue_Score[\"B3\"])\n  print(\"BLEU-4 SCORE IS : \",blue_Score[\"B4\"])\nclass BiLSTM_ATTENTION(nn.Module):\n    def __init__(self, dep_layer_size):\n        super(BiLSTM_ATTENTION, self).__init__()\n        self.attn = nn.Linear(dep_layer_size * 2, dep_layer_size)\n        self.v = nn.Linear(dep_layer_size, 1, bias=False)\n    def forward(self, dep_layer, encoder_outputs):\n        attn_weights = torch.tanh(self.attn(torch.cat((dep_layer, encoder_outputs), dim=2)))\n        energy = self.v(attn_weights)\n        return torch.softmax(energy, dim=1)\ndef printbleu2(bl1,val_data1,val_data_ans1):\n  blue_Score = {\"B1\" : 0, \"B2\" : 0, \"B3\" : 0, \"B4\" : 0}\n  for i in range(len(val_data)):\n    r1 = [val_data_ans1[i]]\n    src = val_data1[i]\n    d1 = calcbleu(bl1,r1,src)\n    blue_Score[\"B1\"]+=comp1(d1['precisions'][0])\n    blue_Score[\"B2\"]+=comp1(d1['precisions'][1])\n    blue_Score[\"B3\"]+=comp1(d1['precisions'][2])\n    blue_Score[\"B4\"]+=comp1(d1['precisions'][3])\n  blue_Score[\"B1\"] = blue_Score[\"B1\"]/(len(val_data1))\n  blue_Score[\"B2\"] = blue_Score[\"B2\"]/(len(val_data1))\n  blue_Score[\"B3\"] = blue_Score[\"B3\"]/(len(val_data1))\n  blue_Score[\"B4\"] = blue_Score[\"B4\"]/(len(val_data1))\n  print(\"BLEU-1 SCORE IS : \",blue_Score[\"B1\"])\n  print(\"BLEU-2 SCORE IS : \",blue_Score[\"B2\"])\n  print(\"BLEU-3 SCORE IS : \",blue_Score[\"B3\"])\n  print(\"BLEU-4 SCORE IS : \",blue_Score[\"B4\"])\nclass Decoder(nn.Module):\n    def __init__(self, dep_layer_size, output_size):\n        super(Decoder, self).__init__()\n        self.dep_layer_size = dep_layer_size\n        self.gru = nn.GRU(dep_layer_size, dep_layer_size)\n        self.fc = nn.Linear(dep_layer_size * 2, output_size)\n        self.attention = Attention(dep_layer_size)\n    def forward(self, input_seq, dep_layer, encoder_outputs):\n        input_seq = input_seq.unsqueeze(0)\n        output, dep_layer = self.gru(input_seq, dep_layer)\n        attn_weights = self.attention(output, encoder_outputs)\n        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n        output = output.squeeze(0)\n        context = context.squeeze(1)\n        output = torch.cat((output, context), 1)\n        output = torch.relu(self.fc(output))\n        return output, dep_layer","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training loop\n\n# train_metrics = []\n\nscaler = torch.cuda.amp.grad_scaler.GradScaler()\nCrossEntropyLoss = torch.nn.CrossEntropyLoss(weight = weights).to(DEVICE)           # unweighted right now\n\nacc_train = Accuracy(task = 'multiclass', num_classes = NUM_CLASSES, average = 'weighted', top_k = 1).to(DEVICE)\nacc_val = Accuracy(task = 'multiclass', num_classes = NUM_CLASSES, average = 'weighted', top_k = 1).to(DEVICE)\n\nrecall_train = Recall(task = 'multiclass', average = 'weighted', num_classes = NUM_CLASSES).to(DEVICE)\nrecall_val = Recall(task = 'multiclass', average = 'weighted', num_classes = NUM_CLASSES).to(DEVICE)\n\nprecision_train = Precision(task = 'multiclass', average = 'weighted', num_classes = NUM_CLASSES).to(DEVICE)\nprecision_val = Precision(task = 'multiclass', average = 'weighted', num_classes = NUM_CLASSES).to(DEVICE)\n\nf1_train = F1Score(task = 'multiclass', average = 'weighted', num_classes = NUM_CLASSES).to(DEVICE)\nf1_val = F1Score(task = 'multiclass', average = 'weighted', num_classes = NUM_CLASSES).to(DEVICE)\n\nfor epoch in range(1, EPOCHS+1):\n    epoch_loss = 0\n    samples = 0\n    #set model to train\n    model.train()\n    for data in (pbar:= tqdm(train_loader)):\n        #zero optim grad\n        optim.zero_grad(set_to_none=True)\n        img, labels = data\n\n        # append to sampels\n        n_batch = len(img)\n        samples+= n_batch\n\n        # to device\n        img = img.to(DEVICE)\n        labels = labels.to(DEVICE)\n\n        #forward step\n        with torch.autocast(device_type = 'cuda', dtype = torch.bfloat16):\n            outputs = model(img)\n            loss = CrossEntropyLoss(outputs, labels)\n        \n\n        # backward step\n        scaler.scale(loss).backward()\n        scaler.step(optim)\n        scaler.update()\n\n        epoch_loss+= (loss.item() * n_batch)\n        pbar.set_description(f\"CE Loss: {epoch_loss/samples}\")\n\n        # accuracy and metrics\n        acc_train(outputs, labels)\n        precision_train(outputs, labels)\n        recall_train(outputs,labels)\n        f1_train(outputs, labels)\n\n    # validation\n    model.eval()\n\n    val_loss = 0\n    val_samples = 0\n    for data in (val_loader):\n        val_img, val_labels = data\n\n        # append to sampels\n        n_batch_val = len(img)\n        val_samples+= n_batch_val\n\n        # to device\n        val_img = val_img.to(DEVICE)\n        val_labels = val_labels.to(DEVICE)\n\n\n        with torch.no_grad():  \n            val_outputs = model(val_img)\n            v_loss = CrossEntropyLoss(val_outputs, val_labels)\n            val_loss+= (v_loss.item() * n_batch_val)\n\n        # metrics\n        acc_val(val_outputs, val_labels)\n        precision_val(val_outputs, val_labels)\n        recall_val(val_outputs, val_labels)\n        f1_val(val_outputs, val_labels)\n\n    logging_dict = {\n        'epoch': epoch,\n        'train_loss': epoch_loss/samples,\n        'val_loss': val_loss/val_samples,\n        \n        \n        'train_acc': acc_train.compute(),\n        'train_rec': recall_train.compute(),\n        'train_prec': precision_train.compute(),\n        'train_f1': f1_train.compute(),\n        \n        'val_acc_top1': acc_val.compute(),\n        'val_rec': recall_val.compute(),\n        'val_prec': precision_val.compute(),\n        'val_f1' : f1_val.compute()\n    }\n    \n    # print('Training Accuracy: {}, Validation Accuracy: {}'.format(logging_dict['train_acc'].item(), logging_dict['val_acc_top1'].item()))\n    wandb.log(logging_dict)\n    \n    # train_metrics.append(logging_dict)\n    \n    acc_train.reset()\n    acc_val.reset()\n    recall_train.reset()\n    recall_val.reset()\n    f1_train.reset()\n    f1_val.reset()\n    precision_train.reset()\n    precision_val.reset()\n    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n    wandb.save(MODEL_SAVE_PATH)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred=give_pred(test_data)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred2=[]\nfor i in pred:\n    pred2.append(remove_tags(i))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l1=test_data[\"targetStereotype\"].tolist()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"printbleu(bl1,l1,pred2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"printbert(ber,l1,pred2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}